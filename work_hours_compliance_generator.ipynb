{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504a9c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################################################################################################################################\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'FOLDER_PATH_gme_compliance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#############################################################################################################################################################\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m today \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp\u001b[38;5;241m.\u001b[39mtoday()\n\u001b[1;32m---> 32\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFOLDER_PATH_gme_compliance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     34\u001b[0m old_file_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpast_lists\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     36\u001b[0m old_file_folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, old_file_folder)\n",
      "File \u001b[1;32m<frozen os>:685\u001b[0m, in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'FOLDER_PATH_gme_compliance'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "import numpy as np\n",
    "\n",
    "import cedars_utils\n",
    "import ast\n",
    "\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
    "\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "\n",
    "print(\"#############################################################################################################################################################\")\n",
    "\n",
    "today = pd.Timestamp.today()\n",
    "\n",
    "folder_path = os.environ[\"FOLDER_PATH_gme_compliance\"]\n",
    "\n",
    "old_file_folder = 'past_lists'\n",
    "\n",
    "old_file_folder_path = os.path.join(folder_path, old_file_folder)\n",
    "\n",
    "# Load Excel files into a DataFrame\n",
    "\n",
    "active_file_name = 'active.xlsx'\n",
    "hours_file_name = 'hours.xlsx'\n",
    "\n",
    "active_file_path = os.path.join(folder_path, active_file_name)\n",
    "hours_file_path = os.path.join(folder_path, hours_file_name)\n",
    "\n",
    "active = pd.read_excel(active_file_path)\n",
    "hours = pd.read_excel(hours_file_path)\n",
    "\n",
    "# load in directors info\n",
    "pd_list_file_name = 'PD_and_PA_report_list.xlsx'\n",
    "pd_list_file_path = os.path.join(folder_path, pd_list_file_name)\n",
    "pd_list = pd.read_excel(pd_list_file_path)\n",
    "\n",
    "\n",
    "# generating new active file, move old into \"past\" folder\n",
    "src_file_name = \"weekly_compliance_email_list.xlsx\"\n",
    "src_file = os.path.join(folder_path, src_file_name)\n",
    "target_folder_name = \"past_lists/old_compliance_list\"\n",
    "target_folder = os.path.join(folder_path, target_folder_name)\n",
    "\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.today().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "weekday = today.weekday()  # Monday=0, ..., Sunday=6\n",
    "\n",
    "# Determine reference date\n",
    "if weekday == 0:  # Monday\n",
    "    # Get previous Thursday\n",
    "    ref_date = today - timedelta(days=4)\n",
    "elif weekday == 3:  # Thursday\n",
    "    # Get previous Monday\n",
    "    ref_date = today - timedelta(days=3)\n",
    "else:\n",
    "    # Default: just use today\n",
    "    ref_date = today\n",
    "\n",
    "# Format the reference date\n",
    "date_str = ref_date.strftime(\"%m_%d_%Y\")\n",
    "\n",
    "# Build new file name\n",
    "base_name, ext = os.path.splitext(os.path.basename(src_file))\n",
    "new_file_name = f\"{base_name}_{date_str}{ext}\"\n",
    "dst_file = os.path.join(target_folder, new_file_name)\n",
    "\n",
    "# Move the file\n",
    "shutil.move(src_file, dst_file)\n",
    "print(f\"Moved file to: {dst_file}\")\n",
    "\n",
    "hours[['Trainee Last Name', 'Trainee First Name']] = hours['Person'].str.split(',', n=1, expand=True)\n",
    "\n",
    "# Remove any leading/trailing spaces\n",
    "hours['Trainee Last Name'] = hours['Trainee Last Name'].str.strip()\n",
    "hours['Trainee First Name'] = hours['Trainee First Name'].str.strip()\n",
    "#rename columns \n",
    "\n",
    "hours_columns = [\"Person's National Provider Identifier\", 'Person', 'Status', 'Program',\n",
    "       'Work Type', 'Start Date/Time', 'End Date/Time', 'Hours Worked',\n",
    "       'Rotation', 'Rotation Start Date', 'Rotation End Date', 'Source',\n",
    "       'Resident Approved', 'Administrator Approved', 'Institution/Location',\n",
    "       'In Violation', 'Violations', 'Rules Violated', 'Comment', 'Comment By',\n",
    "       'Last Update', 'Date Logged', \"Person's Coordinator Email\",\n",
    "       \"Person's Primary E-Mail Address\", \"Person's Program Coordinator\",\n",
    "       \"Person's Program Director\", 'Trainee Last Name', 'Trainee First Name']\n",
    "\n",
    "active_columns = ['ID Number', 'Last Name', 'First Name', 'Middle Name',\n",
    "       \"Person's National Provider Identifier\",\n",
    "       \"Person's Primary E-Mail Address\", 'Department/Division', 'Program',\n",
    "       \"Person's Program Director\", 'Status', \"Person's Program Start Date\",\n",
    "       \"Person's Program End Date\", \"Person's Coordinator Email\",\n",
    "       \"Person's Program Coordinator\"]\n",
    "\n",
    "#build list for email automation\n",
    "table_list_columns = [\"Trainee First Name\", \"Trainee Last Name\", \"Trainee Email\", \"Date of Missing Hours\", \"Week of Missing Hours\", \"Violations\", \"ResQ Violations\",\n",
    "                     \"Program Admin First Name\",\t\"Program Admin Last Name\", \"Program Admin Email\", \"Program Director First Name\", \"Program Director Last Name\", \"Program Director Email\",\n",
    "                     \"80 Hr\", \"Day Off\", \"Call\", \"24+\", \"SB\"]\n",
    "\n",
    "hours_column_update = [\"Person's National Provider Identifier\", 'Person', 'Status', 'Program',\n",
    "       'Work Type', 'Actual Start', 'Actual End', 'Actual Hours Worked', \n",
    "       'Rotation', 'Rotation Start Date', 'Rotation End Date', 'Source', \n",
    "       'Resident Approved', 'Administrator Approved', 'Institution/Location', \n",
    "       'In Violation', 'Violation(s)', 'Rules Violated', 'Comment', 'Comment By',\n",
    "       'Last Update', \"Date Logged\", \"Program Admin Email\", \n",
    "       \"Trainee Email\", \"Person's Program Coordinator\", \n",
    "       \"Person's Program Director\", 'Trainee Last Name', 'Trainee First Name',]\n",
    "\n",
    "active_columns_update = ['ID Number', 'Trainee Last Name', 'Trainee First Name', 'Middle Name',\n",
    "       \"Person's National Provider Identifier\",\n",
    "       \"Trainee Email\", 'Department/Division', 'Program',\n",
    "       \"Person's Program Director\", 'Status', \"Person's Program Start Date\",\n",
    "       \"Person's Program End Date\", \"Program Admin Email\",\n",
    "       \"Person's Program Coordinator\"]\n",
    "\n",
    "\n",
    "#update column names\n",
    "hours.columns = hours_column_update\n",
    "active.columns = active_columns_update\n",
    "\n",
    "hours['Trainee Email'] = hours['Trainee Email'].str.lower()\n",
    "active['Trainee Email'] = active['Trainee Email'].str.lower()\n",
    "\n",
    "hours['Program Admin Email'] = hours['Program Admin Email'].str.lower()\n",
    "active['Program Admin Email'] = active['Program Admin Email'].str.lower()\n",
    "\n",
    "pd_list['programcoordinatoremail'] = pd_list['programcoordinatoremail'].str.lower()\n",
    "active = active[active['Status']!='Chief Resident']\n",
    "pd_list_columns = ['program', 'programtype', 'department', 'programdirector_first_name',\n",
    "       'programdirector_last_name', 'programdirector', 'programdirectoremail',\n",
    "       'programcoordinator', 'programcoordinatoremail']\n",
    "\n",
    "pd_list_columns_update = ['Program', 'programtype', 'department', 'Program Director First Name',\n",
    "       'Program Director Last Name', 'programdirector', 'Program Director Email',\n",
    "       'programcoordinator', 'Program Admin Email']\n",
    "pd_list.columns = pd_list_columns_update\n",
    "# filter down hours based on week of interest\n",
    "# define week of interest\n",
    "\n",
    "# Get today's date (midnight)\n",
    "today = datetime.today().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "# Determine most recent Sunday (start of the current week)\n",
    "# weekday(): Monday=0, Sunday=6 → days_since_sunday = (weekday + 1) % 7\n",
    "days_since_sunday = (today.weekday() + 1) % 7\n",
    "start_of_this_week = today - timedelta(days=days_since_sunday)\n",
    "\n",
    "# Define last week's range (Sunday → next Saturday)\n",
    "start_of_last_week = start_of_this_week - timedelta(days=7)\n",
    "end_of_last_week = start_of_this_week - timedelta(days=1)   # Saturday\n",
    "\n",
    "# Adjust times\n",
    "start_of_last_week = start_of_last_week.replace(hour=0, minute=0, second=0, microsecond=0)  # Sunday 12:00 AM\n",
    "end_of_last_week = end_of_last_week.replace(hour=23, minute=59, second=0, microsecond=0)      # Saturday 11:59 PM\n",
    "\n",
    "\n",
    "# Filter rows between end and start of week\n",
    "mask = (hours['Actual Start'] >= start_of_last_week) & (hours['Actual Start'] <= end_of_last_week)\n",
    "df_last_week = hours.loc[mask].copy() \n",
    "resQ = df_last_week[df_last_week['Work Type']=='ResQ Working']\n",
    "\n",
    "df_last_week['In Violation'] = df_last_week['In Violation'].str.strip().str.lower()\n",
    "\n",
    "valid_yes = ['yes', 'y']\n",
    "\n",
    "violations = df_last_week[df_last_week['In Violation'].isin(valid_yes)]\n",
    "\n",
    "#missing_hours\n",
    "unique_emails_hours_entry = df_last_week[\"Trainee Email\"].unique().tolist()\n",
    "\n",
    "# Convert to set for faster lookup\n",
    "email_set_hours = set(unique_emails_hours_entry)\n",
    "\n",
    "# Get emails in df1 that are NOT in df2\n",
    "emails_not_in_hours = set(active[\"Trainee Email\"]) - email_set_hours\n",
    "\n",
    "# Convert to a list if you want\n",
    "emails_not_in_hours = list(emails_not_in_hours)\n",
    "\n",
    "print(emails_not_in_hours)\n",
    "\n",
    "violations['Violations'] = violations['Actual Start'].dt.strftime('%m/%d/%Y') +' '+ violations['Rules Violated']\n",
    "# group by unique email\n",
    "consolidated_violations = (\n",
    "    violations.groupby(['Trainee Email'], as_index=False)\n",
    "      .agg({\n",
    "          'Trainee First Name': 'first',\n",
    "          'Trainee Last Name': 'first',\n",
    "          'Program Admin Email':'first',\n",
    "          'Program':'first',\n",
    "          'Violations': lambda x: ', '.join(sorted(set(x.dropna())))\n",
    "      })\n",
    ")\n",
    "consolidated_resQ = (\n",
    "    resQ.groupby(['Trainee Email'], as_index=False)\n",
    "      .agg({\n",
    "          'Trainee First Name': 'first',\n",
    "          'Trainee Last Name': 'first',\n",
    "          'Program Admin Email':'first',\n",
    "          'Program':'first',\n",
    "          'Work Type': lambda x: ', '.join(sorted(set(x.dropna())))\n",
    "      })\n",
    ")\n",
    "consolidated_resQ['ResQ Violations'] = 'Yes'\n",
    "consolidated_resQ = consolidated_resQ.drop('Work Type', axis=1)\n",
    "# partial hour inclusion to the missing hours variable \n",
    "\n",
    "#get count of days each day has added hours, if that count is less than 5, they are considered missing hours\n",
    "df_last_week['Shift Date'] = df_last_week['Actual Start'].dt.date\n",
    "days_worked = (\n",
    "    df_last_week.groupby('Trainee Email')['Actual Start']\n",
    "      .nunique()   # count unique dates\n",
    "      .reset_index(name='Days Worked')\n",
    ")\n",
    "\n",
    "less_than_5 = days_worked[days_worked['Days Worked'] < 5]\n",
    "\n",
    "df_filtered = df_last_week[df_last_week['Trainee Email'].isin(less_than_5['Trainee Email'])]\n",
    "\n",
    "df_filtered = df_filtered.drop(columns= 'Shift Date')\n",
    "\n",
    "df_filtered_unique = df_filtered.drop_duplicates(subset='Trainee Email', keep='first')\n",
    "\n",
    "def expand_shift_days(row):\n",
    "    start = row['Actual Start'].normalize()\n",
    "    end = row['Actual End'].normalize()\n",
    "\n",
    "    # Generate daily date range\n",
    "    return pd.date_range(start, end, freq='D').date\n",
    "\n",
    "df_last_week['Days Covered'] = df_last_week.apply(expand_shift_days, axis=1)\n",
    "df_days = df_last_week.explode('Days Covered')\n",
    "\n",
    "days_worked = (\n",
    "    df_days.groupby('Trainee Email')['Days Covered']\n",
    "           .nunique()\n",
    "           .reset_index(name='Days Worked')\n",
    ")\n",
    "\n",
    "less_than_5 = days_worked[days_worked['Days Worked'] < 5]\n",
    "\n",
    "df_filtered = df_last_week[\n",
    "    df_last_week['Trainee Email'].isin(less_than_5['Trainee Email'])\n",
    "]\n",
    "\n",
    "df_filtered_unique = df_filtered.drop_duplicates(\n",
    "    subset='Trainee Email',\n",
    "    keep='first'\n",
    ")\n",
    "\n",
    "consolidated_partial_hours_miss = (\n",
    "    df_filtered_unique.groupby(['Trainee Email'], as_index=False)\n",
    "      .agg({\n",
    "          'Trainee First Name': 'first',\n",
    "          'Trainee Last Name': 'first',\n",
    "          'Program':'first',\n",
    "          'Program Admin Email':'first'\n",
    "      })\n",
    ")\n",
    "\n",
    "consolidated_partial_hours_miss['Week of Missing Hours'] = start_of_last_week.strftime('%m/%d/%Y') +'-' + end_of_last_week.strftime('%m/%d/%Y')\n",
    "#get hours together\n",
    "hours_miss = active[active['Trainee Email'].isin(emails_not_in_hours)]\n",
    "consolidated_hours_miss = (\n",
    "    hours_miss.groupby(['Trainee Email'], as_index=False)\n",
    "      .agg({\n",
    "          'Trainee First Name': 'first',\n",
    "          'Trainee Last Name': 'first',\n",
    "          'Program':'first',\n",
    "          'Program Admin Email':'first'\n",
    "      })\n",
    ")\n",
    "consolidated_hours_miss['Week of Missing Hours'] = start_of_last_week.strftime('%m/%d/%Y') +'-' + end_of_last_week.strftime('%m/%d/%Y')\n",
    "total_consolidated_hours_miss = pd.concat([consolidated_hours_miss,consolidated_partial_hours_miss], ignore_index= True)\n",
    "total_consolidated_hours_miss_unique = total_consolidated_hours_miss.drop_duplicates(subset='Trainee Email', keep='first')\n",
    "#join together \n",
    "table = pd.concat([consolidated_resQ, total_consolidated_hours_miss_unique, consolidated_violations], ignore_index= True)\n",
    "id_cols = ['Trainee Email']\n",
    "\n",
    "# All other columns to keep, filling NaNs where possible\n",
    "value_cols = [col for col in table.columns if col not in id_cols]\n",
    "\n",
    "# Group by email and take the first non-NaN for each column\n",
    "consolidated_df = table.groupby(id_cols, as_index=False).agg(\n",
    "    {col: 'first' for col in value_cols}\n",
    ")\n",
    "columns_to_use = ['Program Admin Email','Program Director First Name', 'Program Director Last Name', 'Program Director Email', 'Program']\n",
    "consolidated_df1 = consolidated_df.merge(pd_list[columns_to_use], \n",
    "                                         on=[\"Program Admin Email\",\"Program\"], how=\"left\")\n",
    "#remove program that do not have \"ACGME\" in title\n",
    "consolidated_df1 = consolidated_df1[consolidated_df1['Program'].str.contains('ACGME')]\n",
    "# remove test cases from jeffrey.mckelvey@cshs.org\t\n",
    "consolidated_df1 = consolidated_df1[consolidated_df1['Trainee Email']!='jeffrey.mckelvey@cshs.org']\n",
    "# Added filter for Pilot Programs\n",
    "pilots = ['NEUROSURG-Neurological Surgery-ACGME', 'Imaging-Diagnostic Radiology-ACGME', 'MED-Pulmonary Disease & Critical Care Medicine-ACGME',\n",
    "          'RAD-Radiation Oncology-ACGME', 'PEDS-Pediatric Medicine-ACGME', 'Surgery-Advanced GI MIS/Bariatric', 'MED-Hospice & Palliative Care Medicine-ACGME',\n",
    "          'OB/GYN-Obstetrics & Gynecology-ACGME', 'MED-Rheumatology-ACGME']\n",
    "consolidated_df1 = consolidated_df1[consolidated_df1['Program'].isin(pilots)]\n",
    "\n",
    "\n",
    "# Load Excel files into a DataFrame\n",
    "\n",
    "active_file_name = 'active.xlsx'\n",
    "hours_file_name = 'hours.xlsx'\n",
    "\n",
    "active_file_path = os.path.join(folder_path, active_file_name)\n",
    "hours_file_path = os.path.join(folder_path, hours_file_name)\n",
    "\n",
    "\n",
    "new_active_file_path = os.path.join(old_file_folder_path, 'old_active_list')\n",
    "new_hours_file_path = os.path.join(old_file_folder_path, 'old_hours_list')\n",
    "\n",
    "date_str = datetime.today().strftime(\"%m_%d_%Y\")  # e.g., \"10_22_2025\"\n",
    "\n",
    "# Build new file name\n",
    "base_name, ext = os.path.splitext(os.path.basename(active_file_name))\n",
    "new_active_file_name = f\"{base_name}_{date_str}{ext}\"\n",
    "\n",
    "# Get the full destination path\n",
    "active_destination_file = os.path.join(new_active_file_path, new_active_file_name)\n",
    "\n",
    "# Move the file\n",
    "shutil.move(active_file_path, active_destination_file)\n",
    "#print(source_file, destination_file)\n",
    "print(f'Moved: {new_active_file_name}')\n",
    "\n",
    "# Build new file name\n",
    "base_name, ext = os.path.splitext(os.path.basename(hours_file_name))\n",
    "new_hours_file_name = f\"{base_name}_{date_str}{ext}\"\n",
    "\n",
    "# Get the full destination path\n",
    "hours_destination_file = os.path.join(new_hours_file_path, new_hours_file_name)\n",
    "\n",
    "\n",
    "shutil.move(hours_file_path, hours_destination_file)\n",
    "#print(source_file, destination_file)\n",
    "print(f'Moved: {new_hours_file_name}')\n",
    "qc_df = (consolidated_df1\n",
    "        .groupby('Program')\n",
    "        .size()\n",
    "        .reset_index(name='Count')\n",
    "        )\n",
    "qc_df['SummaryLine'] = qc_df['Program'] + ' → ' + qc_df['Count'].astype(str) + ' trainees'\n",
    "\n",
    "# Convert 'SummaryLine' column into a single string with newline separators\n",
    "full_summary = '\\n'.join(qc_df['SummaryLine'].astype(str))\n",
    "\n",
    "# Optionally, save it back to Excel in a new column or a single cell\n",
    "# For example, create a new row with the concatenated summary\n",
    "summary_df = pd.DataFrame({'FullSummary': [full_summary]})\n",
    "\n",
    "compliance_list_name = 'weekly_compliance_email_list.xlsx'\n",
    "compliance_list_location = os.path.join(folder_path, compliance_list_name)\n",
    "\n",
    "# --- Save both DataFrames ---\n",
    "with pd.ExcelWriter(compliance_list_location, engine='openpyxl') as writer:\n",
    "    consolidated_df1.to_excel(writer, sheet_name=\"Sheet1\", index=False)\n",
    "    summary_df.to_excel(writer, sheet_name=\"Sheet2\", index=False)\n",
    "\n",
    "# ensure writer handle released\n",
    "try:\n",
    "    del writer\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "\n",
    "import time\n",
    "# small pause to let OS release file lock\n",
    "time.sleep(2)   # try 2 seconds; increase to 3-4 if still locked\n",
    "\n",
    "import gc\n",
    "# force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# --- Reopen workbook to add tables ---\n",
    "wb = load_workbook(compliance_list_location)\n",
    "\n",
    "# --- Table for Sheet1 ---\n",
    "ws1 = wb[\"Sheet1\"]\n",
    "num_rows1 = consolidated_df1.shape[0] + 1\n",
    "num_cols1 = consolidated_df1.shape[1]\n",
    "table_ref1 = f\"A1:{chr(64 + num_cols1)}{num_rows1}\"\n",
    "tab1 = Table(displayName=\"Table1\", ref=table_ref1)\n",
    "style1 = TableStyleInfo(name=\"TableStyleMedium9\", showRowStripes=True)\n",
    "tab1.tableStyleInfo = style1\n",
    "ws1.add_table(tab1)\n",
    "\n",
    "# --- Table for Sheet2 ---\n",
    "ws2 = wb[\"Sheet2\"]\n",
    "num_rows2 = summary_df.shape[0] + 1\n",
    "num_cols2 = summary_df.shape[1]\n",
    "table_ref2 = f\"A1:{chr(64 + num_cols2)}{num_rows2}\"\n",
    "tab2 = Table(displayName=\"Table2\", ref=table_ref2)\n",
    "style2 = TableStyleInfo(name=\"TableStyleMedium9\", showRowStripes=True)\n",
    "tab2.tableStyleInfo = style2\n",
    "ws2.add_table(tab2)\n",
    "\n",
    "# --- Save ---\n",
    "wb.save(compliance_list_location)\n",
    "wb.close()\n",
    "del wb\n",
    "gc.collect()\n",
    "import os\n",
    "try:\n",
    "    with open(compliance_list_location, 'a'):\n",
    "        print(\"File is writable\")\n",
    "except Exception as e:\n",
    "    print(\"File still locked:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

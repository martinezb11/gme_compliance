{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edb273cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized_monthly_compliance.py\n",
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "folder_path = r'C:\\Users\\MartinezB11\\OneDrive - Cedars-Sinai Health System\\Academic Affairs - Data\\GME\\Compliance'\n",
    "old_file_folder = 'past_lists'\n",
    "old_file_folder_path = os.path.join(folder_path, old_file_folder)\n",
    "\n",
    "PILOT_ONLY = True\n",
    "PILOTS = ['NEUROSURG-Neurological Surgery-ACGME', 'Imaging-Diagnostic Radiology-ACGME']\n",
    "OUTPUT_PREFIX = \"monthly_compliance_email_list\"\n",
    "\n",
    "HOURS_COLS_NEW = [\"Person's National Provider Identifier\", 'Person', 'Status', 'Program',\n",
    "       'Work Type', 'Actual Start', 'Actual End', 'Actual Hours Worked',\n",
    "       'Rotation', 'Rotation Start Date', 'Rotation End Date', 'Source',\n",
    "       'Resident Approved', 'Administrator Approved', 'Institution/Location',\n",
    "       'In Violation', 'Violation(s)', 'Rules Violated', 'Comment', 'Comment By',\n",
    "       'Last Update', \"Date Logged\", \"Program Admin Email\",\n",
    "       \"Trainee Email\", \"Person's Program Coordinator\",\n",
    "       \"Person's Program Director\", 'Trainee Last Name', 'Trainee First Name']\n",
    "\n",
    "ACTIVE_COLS_NEW = ['ID Number', 'Trainee Last Name', 'Trainee First Name', 'Middle Name',\n",
    "       \"Person's National Provider Identifier\",\n",
    "       \"Trainee Email\", 'Department/Division', 'Program',\n",
    "       \"Person's Program Director\", 'Status', \"Person's Program Start Date\",\n",
    "       \"Person's Program End Date\", \"Program Admin Email\",\n",
    "       \"Person's Program Coordinator\"]\n",
    "\n",
    "PD_LIST_COLS_NEW = ['Program', 'programtype', 'department', 'Program Director First Name',\n",
    "       'Program Director Last Name', 'programdirector', 'Program Director Email',\n",
    "       'programcoordinator', 'Program Admin Email']\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def ensure_dirs():\n",
    "    os.makedirs(old_file_folder_path, exist_ok=True)\n",
    "    os.makedirs(os.path.join(old_file_folder_path, 'old_active_list'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(old_file_folder_path, 'old_hours_list'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(folder_path, 'past_lists', 'old_compliance_list'), exist_ok=True)\n",
    "\n",
    "def read_inputs():\n",
    "    active = pd.read_excel(os.path.join(folder_path, 'active.xlsx'))\n",
    "    hours = pd.read_excel(os.path.join(folder_path, 'hours.xlsx'))\n",
    "    pd_list = pd.read_excel(os.path.join(folder_path, 'PD_and_PA_report_list.xlsx'))\n",
    "    return active, hours, pd_list\n",
    "\n",
    "def normalize_and_clean(active, hours, pd_list):\n",
    "    # Split 'Person' into first/last names for hours\n",
    "    hours[['Trainee Last Name', 'Trainee First Name']] = hours['Person'].str.split(',', n=1, expand=True)\n",
    "    hours['Trainee Last Name'] = hours['Trainee Last Name'].str.strip()\n",
    "    hours['Trainee First Name'] = hours['Trainee First Name'].str.strip()\n",
    "    \n",
    "    # Rename columns\n",
    "    hours.columns = HOURS_COLS_NEW\n",
    "    active.columns = ACTIVE_COLS_NEW\n",
    "    pd_list.columns = PD_LIST_COLS_NEW\n",
    "\n",
    "    # Lowercase emails\n",
    "    for df, col in [(hours, 'Trainee Email'), (active, 'Trainee Email'),\n",
    "                    (hours, 'Program Admin Email'), (active, 'Program Admin Email'),\n",
    "                    (pd_list, 'Program Admin Email')]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).str.lower().replace({'nan': np.nan})\n",
    "\n",
    "    # Remove Chief Residents\n",
    "    if 'Status' in active.columns:\n",
    "        active = active[active['Status'] != 'Chief Resident']\n",
    "\n",
    "    # Parse datetimes\n",
    "    for c in ['Actual Start', 'Actual End', 'Date Logged', 'Last Update']:\n",
    "        if c in hours.columns:\n",
    "            hours[c] = pd.to_datetime(hours[c], errors='coerce')\n",
    "    return active, hours, pd_list\n",
    "\n",
    "def prev_month_range(reference_date=None):\n",
    "    if reference_date is None:\n",
    "        reference_date = datetime.today().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    first_of_this_month = reference_date.replace(day=1)\n",
    "    end_last_month = first_of_this_month - timedelta(days=1)\n",
    "    start_last_month = end_last_month.replace(day=1)\n",
    "    return start_last_month, end_last_month\n",
    "\n",
    "\n",
    "def generate_full_weeks_for_month(start_month, end_month):\n",
    "    \"\"\"\n",
    "    Generates weekly periods for the month of interest.\n",
    "    Keeps weeks that END inside the month.\n",
    "    Skips weeks that end in the next month.\n",
    "    \"\"\"\n",
    "\n",
    "    # Example: start_month = datetime(2025, 11, 1)\n",
    "    # end_month   = datetime(2025, 11, 30)\n",
    "\n",
    "    month_start = start_month.replace(day=1)\n",
    "    month_end = end_month\n",
    "\n",
    "    # Find first Sunday on or before month_start\n",
    "    first_sunday = month_start - timedelta(days=(month_start.weekday() + 1) % 7)\n",
    "\n",
    "    weeks = []\n",
    "    current_start = first_sunday\n",
    "\n",
    "    while current_start <= month_end:\n",
    "        current_end = current_start + timedelta(days=6)\n",
    "\n",
    "        # --- KEY RULE: Skip if week ends outside target month ---\n",
    "        if current_end.month != start_month.month:\n",
    "            break\n",
    "\n",
    "        # Format week label\n",
    "        week_label = f\"{current_start.strftime('%Y-%m-%d')} to {current_end.strftime('%Y-%m-%d')}\"\n",
    "        weeks.append((current_start, current_end, week_label))\n",
    "\n",
    "        current_start += timedelta(days=7)\n",
    "\n",
    "    return weeks\n",
    "\n",
    "\n",
    "# ---------- Core Processing ----------\n",
    "def process_month(active, hours, pd_list, start_month, end_month):\n",
    "    active = active.copy()\n",
    "    active['Trainee Email'] = active['Trainee Email'].str.lower().str.strip()\n",
    "    hours['Trainee Email'] = hours['Trainee Email'].str.lower().str.strip()\n",
    "    active_emails = set(active['Trainee Email'].dropna())\n",
    "\n",
    "    trainee_info = {}\n",
    "    violations_map = {}\n",
    "    resq_map = {}\n",
    "    missing_weeks_map = {}\n",
    "\n",
    "    # Pre-fill trainee info from active\n",
    "    for _, row in active.iterrows():\n",
    "        email = row.get('Trainee Email')\n",
    "        if pd.isna(email):\n",
    "            continue\n",
    "        trainee_info[email] = {\n",
    "            'Trainee First Name': row.get('Trainee First Name'),\n",
    "            'Trainee Last Name': row.get('Trainee Last Name'),\n",
    "            'Program': row.get('Program'),\n",
    "            'Program Admin Email': row.get('Program Admin Email')\n",
    "        }\n",
    "\n",
    "    weeks = generate_full_weeks_for_month(start_month, end_month)\n",
    "\n",
    "    for ws, we, week_label in weeks:\n",
    "        mask = (hours['Actual Start'] >= ws) & (hours['Actual Start'] <= we)\n",
    "        hours_week = hours.loc[mask].copy()\n",
    "\n",
    "        # RESQ detection\n",
    "        resq_entries = hours_week[hours_week['Work Type'].str.contains('ResQ', na=False, case=False)]\n",
    "        for _, r in resq_entries.iterrows():\n",
    "            email = r.get('Trainee Email')\n",
    "            if pd.isna(email): continue\n",
    "            resq_map[email] = True\n",
    "            if email not in trainee_info:\n",
    "                trainee_info[email] = {\n",
    "                    'Trainee First Name': r.get('Trainee First Name'),\n",
    "                    'Trainee Last Name': r.get('Trainee Last Name'),\n",
    "                    'Program': r.get('Program'),\n",
    "                    'Program Admin Email': r.get('Program Admin Email')\n",
    "                }\n",
    "\n",
    "        # Violations detection\n",
    "        if 'In Violation' in hours_week.columns:\n",
    "            inv_series = hours_week['In Violation'].astype(str).str.strip().str.lower()\n",
    "            valid_yes = inv_series.isin(['yes','y'])\n",
    "            violations_entries = hours_week.loc[valid_yes]\n",
    "            for _, v in violations_entries.iterrows():\n",
    "                email = v.get('Trainee Email')\n",
    "                if pd.isna(email): continue\n",
    "                viol_msg = f\"{v.get('Actual Start').strftime('%m/%d/%Y') if pd.notna(v.get('Actual Start')) else ''} {v.get('Rules Violated','')}\"\n",
    "                violations_map.setdefault(email, set()).add(viol_msg.strip())\n",
    "                if email not in trainee_info:\n",
    "                    trainee_info[email] = {\n",
    "                        'Trainee First Name': v.get('Trainee First Name'),\n",
    "                        'Trainee Last Name': v.get('Trainee Last Name'),\n",
    "                        'Program': v.get('Program'),\n",
    "                        'Program Admin Email': v.get('Program Admin Email')\n",
    "                    }\n",
    "\n",
    "        # Missing hours: no entries\n",
    "        emails_this_week = set(hours_week['Trainee Email'].dropna())\n",
    "        no_entry_emails = active_emails - emails_this_week\n",
    "        for email in no_entry_emails:\n",
    "            missing_weeks_map.setdefault(email, set()).add(week_label)\n",
    "\n",
    "        # Partial coverage (<5 days)\n",
    "        if not hours_week.empty:\n",
    "            def expand_shift_days(row):\n",
    "                s, e = row['Actual Start'], row['Actual End']\n",
    "                if pd.isna(s) or pd.isna(e): return []\n",
    "                start_date, end_date = s.date(), e.date()\n",
    "                if end_date < start_date: return [start_date]\n",
    "                return list(pd.date_range(start_date, end_date).date)\n",
    "            hours_week['Days Covered'] = hours_week.apply(expand_shift_days, axis=1)\n",
    "            df_days = hours_week.explode('Days Covered')\n",
    "            days_worked = df_days.groupby('Trainee Email')['Days Covered'].nunique().reset_index()\n",
    "            partials = days_worked[days_worked['Days Covered'] < 5]\n",
    "            for _, p in partials.iterrows():\n",
    "                email = p['Trainee Email']\n",
    "                missing_weeks_map.setdefault(email, set()).add(week_label)\n",
    "\n",
    "    # Build final DataFrame — only include trainees who have at least one issue\n",
    "    all_emails = set(trainee_info.keys()) | set(violations_map.keys()) | set(resq_map.keys()) | set(missing_weeks_map.keys())\n",
    "\n",
    "    # Keep only emails that actually have a problem\n",
    "    def has_issue(email):\n",
    "        if email in resq_map and resq_map.get(email, False):\n",
    "            return True\n",
    "        if email in violations_map and violations_map.get(email):\n",
    "            return True\n",
    "        if email in missing_weeks_map and missing_weeks_map.get(email):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    filtered_emails = {e for e in all_emails if e is not None and not pd.isna(e) and has_issue(e)}\n",
    "\n",
    "    rows = []\n",
    "    for email in sorted(filtered_emails):\n",
    "        info = trainee_info.get(email, {})\n",
    "        rows.append({\n",
    "            'Trainee Email': email,\n",
    "            'Trainee First Name': info.get('Trainee First Name'),\n",
    "            'Trainee Last Name': info.get('Trainee Last Name'),\n",
    "            'Program': info.get('Program'),\n",
    "            'Program Admin Email': info.get('Program Admin Email'),\n",
    "            'ResQ Violations': 'Yes' if resq_map.get(email, False) else np.nan,\n",
    "            'Violations': ', '.join(sorted(violations_map.get(email, []))) if violations_map.get(email) else np.nan,\n",
    "            'Week(s) of Missing Hours': ', '.join(sorted(missing_weeks_map.get(email, []))) if missing_weeks_map.get(email) else np.nan\n",
    "        })\n",
    "\n",
    "    consolidated_df = pd.DataFrame(rows)\n",
    "\n",
    "    # Optional pilot filter\n",
    "    if PILOT_ONLY:\n",
    "        consolidated_df = consolidated_df[consolidated_df['Program'].isin(PILOTS)]\n",
    "\n",
    "    return consolidated_df\n",
    "\n",
    "# ---------- Output & Save ----------\n",
    "def save_output(consolidated_df, start_month, end_month, program_counts_df):\n",
    "    month_label_short = start_month.strftime(\"%m_%Y\")\n",
    "    output_name = f\"{OUTPUT_PREFIX}_{month_label_short}.xlsx\"\n",
    "    out_path = os.path.join(folder_path, output_name)\n",
    "\n",
    "    # QC summary\n",
    "    qc_df = consolidated_df.groupby('Program').size().reset_index(name='Count')\n",
    "    qc_df['SummaryLine'] = qc_df['Program'] + ' → ' + qc_df['Count'].astype(str) + ' trainees'\n",
    "    full_summary = '\\n'.join(qc_df['SummaryLine'].astype(str))\n",
    "    summary_df = pd.DataFrame({'FullSummary': [full_summary]})\n",
    "\n",
    "    # Save Excel\n",
    "    with pd.ExcelWriter(out_path, engine='openpyxl') as writer:\n",
    "        consolidated_df.to_excel(writer, sheet_name=\"Sheet1\", index=False)\n",
    "        summary_df.to_excel(writer, sheet_name=\"Sheet2\", index=False)\n",
    "        program_counts_df.to_excel(writer, sheet_name='Program Counts', index=False)\n",
    "\n",
    "\n",
    "    wb = load_workbook(out_path)\n",
    "    ws1 = wb[\"Sheet1\"]\n",
    "    ws2 = wb[\"Sheet2\"]\n",
    "\n",
    "    # Add tables\n",
    "    num_rows1, num_cols1 = consolidated_df.shape[0] + 1, consolidated_df.shape[1] if consolidated_df.shape[1] > 0 else 1\n",
    "    tab1 = Table(displayName=\"Table1\", ref=f\"A1:{chr(64+num_cols1)}{num_rows1}\")\n",
    "    tab1.tableStyleInfo = TableStyleInfo(name=\"TableStyleMedium9\", showRowStripes=True)\n",
    "    ws1.add_table(tab1)\n",
    "\n",
    "    num_rows2, num_cols2 = summary_df.shape[0] + 1, summary_df.shape[1]\n",
    "    tab2 = Table(displayName=\"Table2\", ref=f\"A1:{chr(64+num_cols2)}{num_rows2}\")\n",
    "    tab2.tableStyleInfo = TableStyleInfo(name=\"TableStyleMedium9\", showRowStripes=True)\n",
    "    ws2.add_table(tab2)\n",
    "\n",
    "    wb.save(out_path)\n",
    "    wb.close()\n",
    "    logging.info(f\"Saved output to {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "# ---------- Output & Save ----------\n",
    "def save_output(consolidated_df, start_month, end_month, program_counts_df, folder_path, OUTPUT_PREFIX):\n",
    "    month_label_short = start_month.strftime(\"%m_%Y\")\n",
    "    output_name = f\"{OUTPUT_PREFIX}_{month_label_short}.xlsx\"\n",
    "    out_path = os.path.join(folder_path, output_name)\n",
    "\n",
    "    # QC summary\n",
    "    qc_df = consolidated_df.groupby('Program').size().reset_index(name='Count')\n",
    "    qc_df['SummaryLine'] = qc_df['Program'] + ' → ' + qc_df['Count'].astype(str) + ' trainees'\n",
    "    full_summary = '\\n'.join(qc_df['SummaryLine'].astype(str))\n",
    "    summary_df = pd.DataFrame({'FullSummary': [full_summary]})\n",
    "\n",
    "    # --- Save Excel using pandas.ExcelWriter ---\n",
    "    with pd.ExcelWriter(out_path, engine='openpyxl') as writer:\n",
    "        consolidated_df.to_excel(writer, sheet_name=\"Sheet1\", index=False)\n",
    "        summary_df.to_excel(writer, sheet_name=\"Sheet2\", index=False)\n",
    "        program_counts_df.to_excel(writer, sheet_name='Program Counts', index=False)\n",
    "\n",
    "    # --- Reopen with openpyxl to add tables ---\n",
    "    wb = load_workbook(out_path)\n",
    "\n",
    "    # Sheet1 table\n",
    "    ws1 = wb[\"Sheet1\"]\n",
    "    num_rows1 = consolidated_df.shape[0] + 1\n",
    "    num_cols1 = consolidated_df.shape[1] if consolidated_df.shape[1] > 0 else 1\n",
    "    tab1 = Table(displayName=\"Table1\", ref=f\"A1:{chr(64+num_cols1)}{num_rows1}\")\n",
    "    tab1.tableStyleInfo = TableStyleInfo(name=\"TableStyleMedium9\", showRowStripes=True)\n",
    "    ws1.add_table(tab1)\n",
    "\n",
    "    # Sheet2 table\n",
    "    ws2 = wb[\"Sheet2\"]\n",
    "    num_rows2, num_cols2 = summary_df.shape[0] + 1, summary_df.shape[1]\n",
    "    tab2 = Table(displayName=\"Table2\", ref=f\"A1:{chr(64+num_cols2)}{num_rows2}\")\n",
    "    tab2.tableStyleInfo = TableStyleInfo(name=\"TableStyleMedium9\", showRowStripes=True)\n",
    "    ws2.add_table(tab2)\n",
    "\n",
    "    # Program Counts table\n",
    "    ws3 = wb[\"Program Counts\"]\n",
    "    num_rows3, num_cols3 = program_counts_df.shape[0] + 1, program_counts_df.shape[1]\n",
    "    tab3 = Table(displayName=\"Table3\", ref=f\"A1:{chr(64+num_cols3)}{num_rows3}\")\n",
    "    tab3.tableStyleInfo = TableStyleInfo(name=\"TableStyleMedium9\", showRowStripes=True)\n",
    "    ws3.add_table(tab3)\n",
    "\n",
    "    # Save and close workbook\n",
    "    wb.save(out_path)\n",
    "    wb.close()\n",
    "    del wb\n",
    "    gc.collect()  # release file handles\n",
    "\n",
    "    # Optional: test file is writable\n",
    "    try:\n",
    "        with open(out_path, 'a'):\n",
    "            logging.info(f\"File is writable and ready for sync: {out_path}\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"File still locked: {e}\")\n",
    "\n",
    "    logging.info(f\"Saved output to {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "def archive_inputs():\n",
    "    date_str = datetime.today().strftime(\"%m_%d_%Y\")\n",
    "    active_file = os.path.join(folder_path, 'active.xlsx')\n",
    "    hours_file = os.path.join(folder_path, 'hours.xlsx')\n",
    "\n",
    "    active_dest = os.path.join(old_file_folder_path, 'old_active_list', f\"active_{date_str}.xlsx\")\n",
    "    hours_dest = os.path.join(old_file_folder_path, 'old_hours_list', f\"hours_{date_str}.xlsx\")\n",
    "\n",
    "    for src, dst in [(active_file, active_dest), (hours_file, hours_dest)]:\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dst)\n",
    "            logging.info(f\"Moved {src} -> {dst}\")\n",
    "        else:\n",
    "            logging.warning(f\"File not found, not moved: {src}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "825ce65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 10:50:58,968 INFO Starting monthly compliance processing...\n",
      "2025-12-01 10:51:01,283 INFO Analyzing previous month: 2025-11-01 -> 2025-11-30\n",
      "2025-12-01 10:51:01,984 INFO File is writable and ready for sync: C:\\Users\\MartinezB11\\OneDrive - Cedars-Sinai Health System\\Academic Affairs - Data\\GME\\Compliance\\monthly_compliance_email_list_11_2025.xlsx\n",
      "2025-12-01 10:51:01,984 INFO Saved output to C:\\Users\\MartinezB11\\OneDrive - Cedars-Sinai Health System\\Academic Affairs - Data\\GME\\Compliance\\monthly_compliance_email_list_11_2025.xlsx\n",
      "2025-12-01 10:51:01,984 INFO Moved C:\\Users\\MartinezB11\\OneDrive - Cedars-Sinai Health System\\Academic Affairs - Data\\GME\\Compliance\\active.xlsx -> C:\\Users\\MartinezB11\\OneDrive - Cedars-Sinai Health System\\Academic Affairs - Data\\GME\\Compliance\\past_lists\\old_active_list\\active_12_01_2025.xlsx\n",
      "2025-12-01 10:51:02,334 INFO Moved C:\\Users\\MartinezB11\\OneDrive - Cedars-Sinai Health System\\Academic Affairs - Data\\GME\\Compliance\\hours.xlsx -> C:\\Users\\MartinezB11\\OneDrive - Cedars-Sinai Health System\\Academic Affairs - Data\\GME\\Compliance\\past_lists\\old_hours_list\\hours_12_01_2025.xlsx\n",
      "2025-12-01 10:51:02,334 INFO Processing complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- Main ----------\n",
    "def main():\n",
    "    logging.info(\"Starting monthly compliance processing...\")\n",
    "    ensure_dirs()\n",
    "    active, hours, pd_list = read_inputs()\n",
    "    active, hours, pd_list = normalize_and_clean(active, hours, pd_list)\n",
    "\n",
    "    start_month, end_month = prev_month_range()\n",
    "    logging.info(f\"Analyzing previous month: {start_month.date()} -> {end_month.date()}\")\n",
    "\n",
    "    # ---------- 1. Create consolidated_df ----------\n",
    "    consolidated_df = process_month(active, hours, pd_list, start_month, end_month)\n",
    "\n",
    "    # ---------- 2. Clean Program column for merging ----------\n",
    "    consolidated_df['Program'] = consolidated_df['Program'].astype(str).str.strip()\n",
    "    programs_info = pd_list.copy()\n",
    "    programs_info['Program'] = programs_info['Program'].astype(str).str.strip()\n",
    "\n",
    "    # ---------- 3. Prepare program/director/admin info from pd_list ----------\n",
    "    # Ensure all needed columns exist\n",
    "    for col in ['Program Director First Name', 'Program Director Last Name', 'Program Director Email',\n",
    "                'programcoordinator', 'Program Admin Email']:\n",
    "        if col not in programs_info.columns:\n",
    "            programs_info[col] = np.nan\n",
    "\n",
    "    # Split 'programcoordinator' into First/Last\n",
    "    programs_info['programcoordinator'] = programs_info['programcoordinator'].fillna('')\n",
    "    def split_coordinator(x):\n",
    "        parts = x.split(',', 1)\n",
    "        if len(parts) == 2:\n",
    "            last, first = parts\n",
    "        else:\n",
    "            last = parts[0]\n",
    "            first = ''\n",
    "        return pd.Series([last.strip(), first.strip()])\n",
    "\n",
    "    programs_info[['Program Admin Last Name', 'Program Admin First Name']] = programs_info['programcoordinator'].apply(split_coordinator)\n",
    "\n",
    "\n",
    "    # Keep only needed columns\n",
    "    pd_info = programs_info[['Program', 'Program Director First Name', 'Program Director Last Name',\n",
    "                            'Program Director Email', 'Program Admin First Name', 'Program Admin Last Name',\n",
    "                            'Program Admin Email']]\n",
    "\n",
    "    # Deduplicate one row per Program\n",
    "    pd_info = pd_info.drop_duplicates(subset=['Program'])\n",
    "\n",
    "    # ---------- 4. Merge info into consolidated_df (Sheet1) ----------\n",
    "    # Clean Program columns for merge\n",
    "    consolidated_df['Program_clean'] = consolidated_df['Program'].str.lower().str.strip()\n",
    "    pd_info['Program_clean'] = pd_info['Program'].str.lower().str.strip()\n",
    "\n",
    "\n",
    "    consolidated_df = consolidated_df.merge(pd_info, on='Program_clean', how='left', suffixes=('', '_info'))\n",
    "\n",
    "\n",
    "    consolidated_df = consolidated_df.drop(columns=['Program_clean'])\n",
    "\n",
    "    # ---------- 5. Build program_counts_df (Sheet2) ----------\n",
    "    all_programs = sorted(consolidated_df['Program'].astype(str).str.strip().unique())\n",
    "    program_counts = consolidated_df['Program'].value_counts().reindex(all_programs, fill_value=0)\n",
    "\n",
    "    program_counts_df = pd.DataFrame({\n",
    "        'Program': program_counts.index,\n",
    "        'Count': program_counts.values\n",
    "    })\n",
    "\n",
    "    # Merge program/director/admin info into program_counts_df\n",
    "    program_counts_df['Program_clean'] = program_counts_df['Program'].str.lower().str.strip()\n",
    "    program_counts_df = program_counts_df.merge(pd_info, on='Program_clean', how='left')\n",
    "    program_counts_df = program_counts_df.drop(columns=['Program_clean'])\n",
    "\n",
    "    save_output(consolidated_df, start_month, end_month, program_counts_df, folder_path, OUTPUT_PREFIX)\n",
    "    archive_inputs()\n",
    "    logging.info(\"Processing complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99add58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
